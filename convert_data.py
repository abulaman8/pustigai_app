import os
import json
import re
import pprint
import argparse
import math

# Define the set of fields that constitute intellectual property (IP).
IP_FIELDS = {
    'ub_1', 'lb_1', 'sub_rep_1', 'sub_state_1',
    'sub_ub_11', 'sub_lb_11', 'sub_ub_12', 'sub_lb_12',
    'ub_2', 'lb_2', 'sub_rep_2', 'sub_state_2',
    'sub_ub_21', 'sub_lb_21', 'sub_ub_22', 'sub_lb_22',
    'sub_ub_23', 'sub_lb_23', 'sub_ub_24', 'sub_lb_24',
    'ub_3', 'lb_3', 'sub_rep_3', 'sub_state_3'
}

# The number of files to split the IP data into.
NUM_SPLIT_FILES = 4


def clean_exercise_name(source_filename):
    """Cleans the exercise name extracted from the 'source' field."""
    name = os.path.splitext(source_filename)[0]
    name = re.sub(r'^\d+\s*\.\s*', '', name)
    name = name.replace('_', ' ').replace('.', ' ')
    name = ' '.join(word.capitalize() for word in name.split())
    return name.strip()


def process_directory(input_dir):
    """
    Processes all JSON files, corrects their format, and separates them into
    multiple IP data files and a single database seed file.
    """
    db_seed_data = {}

    # Initialize a list of dictionaries, one for each output file
    split_ip_data = [{} for _ in range(NUM_SPLIT_FILES)]

    print(f"Starting processing of directory: {input_dir}")

    if not os.path.isdir(input_dir):
        print(f"Error: Directory not found at '{input_dir}'")
        return None, None

    # Get a sorted list of files to ensure consistent processing order
    files_to_process = sorted(
        [f for f in os.listdir(input_dir) if f.endswith('.json')])

    if not files_to_process:
        print("No JSON files found in the directory.")
        return None, None

    total_files = len(files_to_process)
    # Calculate chunk size, rounding up
    chunk_size = math.ceil(total_files / NUM_SPLIT_FILES)
    print(f"Found {total_files} JSON files. Splitting into {NUM_SPLIT_FILES} parts of ~{chunk_size} exercises each.")

    for i, filename in enumerate(files_to_process):
        file_path = os.path.join(input_dir, filename)
        try:
            exercise_id = os.path.splitext(filename)[0]

            with open(file_path, 'r') as f:
                raw_data = json.load(f)

            if len(raw_data) != 1:
                print(
                    f"Warning: Skipping {filename}, expected 1 top-level key but found {len(raw_data)}.")
                continue

            exercise_data = list(raw_data.values())[0]

            if 'source' not in exercise_data:
                print(
                    f"Warning: Skipping {filename}, 'source' field not found.")
                continue

            # === FIX THE TYPO START ===
            # Check for the incorrect key 'wait_time' and rename it to 'wait_timer'
            if 'wait_time' in exercise_data:
                print(f"Found and corrected 'wait_time' typo in {filename}")
                exercise_data['wait_timer'] = exercise_data.pop('wait_time')
            # === FIX THE TYPO END ===

            # Create the full, clean data object for this exercise
            clean_data = {'id': exercise_id,
                          'name': clean_exercise_name(exercise_data['source'])}
            clean_data.update(exercise_data)

            # Determine which split file this exercise belongs to
            part_index = i // chunk_size
            split_ip_data[part_index][exercise_id] = clean_data

            # Create the database-only version by removing IP fields
            db_exercise = clean_data.copy()
            for field in IP_FIELDS:
                db_exercise.pop(field, None)

            db_seed_data[exercise_id] = db_exercise

            # Removed the print statement from here to reduce noise

        except json.JSONDecodeError:
            print(f"Error: Could not decode JSON from {filename}. Skipping.")
        except Exception as e:
            print(
                f"An unexpected error occurred with {filename}: {e}. Skipping.")

    print(f"\nSuccessfully processed {len(files_to_process)} files.")
    return split_ip_data, db_seed_data


def write_output_files(split_ip_data, db_data):
    """Writes the processed data into multiple IP files and one DB seed file."""

    for i, ip_part_dict in enumerate(split_ip_data):
        part_num = i + 1
        output_ip_file = f'generated_exercise_ip_data_part{part_num}.py'
        dict_name = f'exercises_db_part{part_num}'
        with open(output_ip_file, 'w') as f:
            f.write(
                f"# This file was auto-generated by convert_exercise_json.py (Part {part_num}/{NUM_SPLIT_FILES})\n")
            f.write(
                "# It contains a portion of the complete exercise data, including sensitive IP.\n")
            f.write(
                f"# This file should be placed in 'src/', renamed to 'exercise_data_part{part_num}.py', obfuscated, and then removed from 'src/'.\n\n")
            f.write(f"{dict_name} = ")
            f.write(pprint.pformat(ip_part_dict, indent=4))
        print(f"Successfully created IP data file: {output_ip_file}")

    output_db_file = 'generated_db_seed_data.py'
    with open(output_db_file, 'w') as f:
        f.write("# This file was auto-generated by convert_exercise_json.py\n")
        f.write("# It contains only the non-sensitive data for database seeding.\n")
        f.write(
            "# Copy the 'exercises_db' dictionary from this file and paste it into 'init_db.py'.\n\n")
        f.write("exercises_db = ")
        f.write(pprint.pformat(db_data, indent=4))
    print(
        f"Successfully created consolidated database seed file: {output_db_file}")


def main():
    parser = argparse.ArgumentParser(
        description="Convert corrupt exercise JSON files into clean Python dictionaries.")
    parser.add_argument("input_dir", type=str,
                        help="The path to the directory containing the JSON files.")
    args = parser.parse_args()

    split_data, db_data = process_directory(args.input_dir)

    if split_data and db_data:
        write_output_files(split_data, db_data)
        print("\nConversion complete!")
    else:
        print("\nConversion failed. No files were generated.")


if __name__ == "__main__":
    main()
